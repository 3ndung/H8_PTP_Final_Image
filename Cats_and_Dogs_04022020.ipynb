{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Cats_and_Dogs_04022020.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TBFXQGKYUc4X"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "1z4xy2gTUc4a",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZQxwRgi6V8u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FE7KNzPPVrVV"
      },
      "source": [
        "# Image classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KwQtSOz0VrVX"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/images/classification\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/images/classification.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gN7G9GFmVrVY"
      },
      "source": [
        "This tutorial shows how to classify cats or dogs from images. It builds an image classifier using a `tf.keras.Sequential` model and load data using `tf.keras.preprocessing.image.ImageDataGenerator`. You will get some practical experience and develop intuition for the following concepts:\n",
        "\n",
        "* Building _data input pipelines_ using the `tf.keras.preprocessing.image.ImageDataGenerator` class to efficiently work with data on disk to use with the model.\n",
        "* _Overfitting_ —How to identify and prevent it.\n",
        "* _Data augmentation_ and _dropout_ —Key techniques to fight overfitting in computer vision tasks to incorporate into the data pipeline and image classifier model.\n",
        "\n",
        "This tutorial follows a basic machine learning workflow:\n",
        "\n",
        "1. Examine and understand data\n",
        "2. Build an input pipeline\n",
        "3. Build the model\n",
        "4. Train the model\n",
        "5. Test the model\n",
        "6. Improve the model and repeat the process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zF9uvbXNVrVY"
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VddxeYBEVrVZ"
      },
      "source": [
        "Let's start by importing the required packages. The `os` package is used to read files and directory structure, NumPy is used to convert python list to numpy array and to perform required matrix operations and `matplotlib.pyplot` to plot the graph and display images in the training and validation data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rtPGh2MAVrVa",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Jlchl4x2VrVg"
      },
      "source": [
        "Import Tensorflow and the Keras classes needed to construct our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E82grprdYPI0",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L1WtoaOHVrVh",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UZZI6lNkVrVm"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DPHx8-t-VrVo"
      },
      "source": [
        "Begin by downloading the dataset. This tutorial uses a filtered version of <a href=\"https://www.kaggle.com/c/dogs-vs-cats/data\" target=\"_blank\">Dogs vs Cats</a> dataset from Kaggle. Download the archive version of the dataset and store it in the \"/tmp/\" directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Giv0wMQzVrVw"
      },
      "source": [
        "The dataset has the following directory structure:\n",
        "\n",
        "<pre>\n",
        "<b>cats_and_dogs_filtered</b>\n",
        "|__ <b>train</b>\n",
        "    |______ <b>cats</b>: [cat.0.jpg, cat.1.jpg, cat.2.jpg ....]\n",
        "    |______ <b>dogs</b>: [dog.0.jpg, dog.1.jpg, dog.2.jpg ...]\n",
        "|__ <b>validation</b>\n",
        "    |______ <b>cats</b>: [cat.2000.jpg, cat.2001.jpg, cat.2002.jpg ....]\n",
        "    |______ <b>dogs</b>: [dog.2000.jpg, dog.2001.jpg, dog.2002.jpg ...]\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yuonBXBRCR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "PATH ='/content/drive/My Drive/DOG_N_CAT/cats_and_dogs_filtered/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VpmywIlsVrVx"
      },
      "source": [
        "After extracting its contents, assign variables with the proper file path for the training and validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sRucI3QqVrVy",
        "colab": {}
      },
      "source": [
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "test_dir = os.path.join(PATH,'test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Utv3nryxVrV0",
        "colab": {}
      },
      "source": [
        "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZdrHHTy2VrV3"
      },
      "source": [
        "### Understand the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LblUYjl-VrV3"
      },
      "source": [
        "Let's look at how many cats and dogs images are in the training and validation directory:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vc4u8e9hVrV4",
        "colab": {}
      },
      "source": [
        "num_cats_tr = len(os.listdir(train_cats_dir))\n",
        "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
        "\n",
        "num_cats_val = len(os.listdir(validation_cats_dir))\n",
        "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
        "\n",
        "total_train = num_cats_tr + num_dogs_tr\n",
        "total_val = num_cats_val + num_dogs_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g4GGzGt0VrV7",
        "colab": {}
      },
      "source": [
        "print('total training cat images:', num_cats_tr)\n",
        "print('total training dog images:', num_dogs_tr)\n",
        "\n",
        "print('total validation cat images:', num_cats_val)\n",
        "print('total validation dog images:', num_dogs_val)\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8Lp-0ejxOtP1"
      },
      "source": [
        "For convenience, set up variables to use while pre-processing the dataset and training the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3NqNselLVrWA",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150\n",
        "IMG_SIZE = (IMG_WIDTH, IMG_HEIGHT)\n",
        "IMG_CHANELS = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUuZXMyNUkoB",
        "colab_type": "text"
      },
      "source": [
        "# MAKE_MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rLO7yhLlVrWu"
      },
      "source": [
        "## Overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UOoVpxFwVrWy"
      },
      "source": [
        "## Data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wn_QLciWVrWy"
      },
      "source": [
        "Overfitting generally occurs when there are a small number of training examples. One way to fix this problem is to augment the dataset so that it has a sufficient number of training examples. Data augmentation takes the approach of generating more training data from existing training samples by augmenting the samples using random transformations that yield believable-looking images. The goal is the model will never see the exact same picture twice during training. This helps expose the model to more aspects of the data and generalize better.\n",
        "\n",
        "Implement this in `tf.keras` using the `ImageDataGenerator` class. Pass  different transformations to the dataset and it will take care of applying it during the training process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "usS13KCNVrXd"
      },
      "source": [
        "### Put it all together"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OC8fIsalVrXd"
      },
      "source": [
        "Apply all the previous augmentations. Here, you applied rescale, 45 degree rotation, width shift, height shift, horizontal flip and zoom augmentation to the training images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gnr2xujaVrXe",
        "colab": {}
      },
      "source": [
        "image_gen_train = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=45,\n",
        "                    width_shift_range=.15,\n",
        "                    height_shift_range=.15,\n",
        "                    horizontal_flip=True,\n",
        "                    zoom_range=0.5\n",
        "                    )\n",
        "\n",
        "image_gen_val = ImageDataGenerator(rescale=1./255)\n",
        "image_gen_test = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K0Efxy7EVrXh",
        "colab": {}
      },
      "source": [
        "train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n",
        "                                                     directory=train_dir,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='binary')\n",
        "val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,\n",
        "                                                 directory=validation_dir,\n",
        "                                                 target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                 class_mode='binary')\n",
        "test_data_gen = image_gen_train.flow_from_directory(batch_size=1,\n",
        "                                                     directory=test_dir,\n",
        "                                                     shuffle=False,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47kF-zfiTJ5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AW-pV5awVrXl"
      },
      "source": [
        "Visualize how a single image would look five different times when passing these augmentations randomly to the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z2m68eMhVrXm",
        "colab": {}
      },
      "source": [
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yQGhdqHFVrXx"
      },
      "source": [
        "## Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2Iq5TAH_VrXx"
      },
      "source": [
        "Another technique to reduce overfitting is to introduce *dropout* to the network. It is a form of *regularization* that forces the weights in the network to take only small values, which makes the distribution of weight values more regular and the network can reduce overfitting on small training examples. Dropout is one of the regularization technique used in this tutorial\n",
        "\n",
        "When you apply dropout to a layer it randomly drops out (set to zero) number of output units from the applied layer during the training process. Dropout takes a fractional number as its input value, in the form such as 0.1, 0.2, 0.4, etc. This means dropping out 10%, 20% or 40% of the output units randomly from the applied layer.\n",
        "\n",
        "When appling 0.1 dropout to a certain layer, it randomly kills 10% of the output units in each training epoch.\n",
        "\n",
        "Create a network architecture with this new dropout feature and apply it to different convolutions and fully-connected layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DyxxXRmVVrXy"
      },
      "source": [
        "## Creating a new network with Dropouts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1Ba2LjtkVrXy"
      },
      "source": [
        "Here, you apply dropout to first and last max pool layers. Applying dropout will randomly set 20% of the neurons to zero during each training epoch. This helps to avoid overfitting on the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2fjio8EsVrXz",
        "colab": {}
      },
      "source": [
        "model_new = Sequential([\n",
        "    Conv2D(128, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
        "    Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Dropout(0.2),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Dropout(0.2),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_new.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_new.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tpTgIxWAVrX0"
      },
      "source": [
        "### Compile the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1osvc_iTVrX1"
      },
      "source": [
        "After introducing dropouts to the network, compile the model and view the layers summary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7KiDshEUVrX6"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NFj0oVqVVrX6"
      },
      "source": [
        "After successfully introducing data augmentations to the training examples and adding dropouts to the network, train this new network:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GWxHs_luVrX7",
        "colab": {}
      },
      "source": [
        "history = model_new.fit_generator(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=total_train // batch_size,\n",
        "    #epochs=50,\n",
        "    #epochs=50,\n",
        "    #epochs=50,\n",
        "    #epochs=50,\n",
        "    epochs=100,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=total_val // batch_size\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bbdyqZdxVrYA"
      },
      "source": [
        "### Visualize the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OgvF2nt7OtR7"
      },
      "source": [
        "Visualize the new model after training, you can see that there is significantly less overfitting than before. The accuracy should go up after training the model for more epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7BTeMuNAVrYC",
        "colab": {}
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(100)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxGnErGqz0V3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_new.save('/content/drive/My Drive/DOG_N_CAT/BAGUS_05022020_1705_val_acc_07679.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekEuRegxtGoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4aPgQhBse3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = tf.keras.preprocessing.image.load_img('/content/drive/My Drive/DOG_N_CAT/cats_and_dogs_filtered/test/cat.419.jpg',target_size=(150, 150))\n",
        "img = np.asarray(img)\n",
        "plt.imshow(img)\n",
        "\n",
        "img = np.expand_dims(img, axis=0)\n",
        "\n",
        "result = model_new.predict_classes(img)\n",
        "plt.xlabel([\"KOCENG\" if int(result) == 0 else \"ANJENG\"])\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6plPbm9u6J9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = tf.keras.preprocessing.image.load_img('/content/drive/My Drive/DOG_N_CAT/cats_and_dogs_filtered/test/dog.745.jpg',target_size=(150, 150))\n",
        "img = np.asarray(img)\n",
        "plt.imshow(img)\n",
        "\n",
        "img = np.expand_dims(img, axis=0)\n",
        "\n",
        "result = model_new.predict_classes(img)\n",
        "plt.xlabel(\"KOCENG\" if int(result) == 0 else \"ANJENG\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5At5JwznxtSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = tf.keras.preprocessing.image.load_img('/content/drive/My Drive/DOG_N_CAT/cats_and_dogs_filtered/test/dog.900.jpg',target_size=(150, 150))\n",
        "img = np.asarray(img)\n",
        "plt.imshow(img)\n",
        "\n",
        "img = np.expand_dims(img, axis=0)\n",
        "\n",
        "result = model_new.predict_classes(img)\n",
        "plt.xlabel(\"KOCENG\" if int(result) == 0 else \"ANJENG\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3YRL8kfz4ta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.axes as axes\n",
        "\n",
        "\n",
        "\n",
        "DATA_LOAD = tf.keras.models.load_model('/content/drive/My Drive/DOG_N_CAT/BAGUS_04022020_1706_val_acc_077.h5')\n",
        "\n",
        "\n",
        "img = tf.keras.preprocessing.image.load_img('/content/drive/My Drive/DOG_N_CAT/cats_and_dogs_filtered/test/cat.180.jpg',target_size=(150, 150))\n",
        "img = np.asarray(img)\n",
        "plt.imshow(img)\n",
        "\n",
        "img = np.expand_dims(img, axis=0)\n",
        "\n",
        "result = DATA_LOAD.predict_classes(img)\n",
        "\n",
        "plt.xlabel(\"KOCENG\" if int(result) == 0 else \"ANJENG\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu7blszwZ9e3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxXt5XinGplA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "OMG = []\n",
        "OMJ = []\n",
        "\n",
        "TAMPOL = \"/content/drive/My Drive/DOG_N_CAT/cats_and_dogs_filtered/test/\"\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/DOG_N_CAT/cats_and_dogs_filtered/test/\")\n",
        "for file in glob.glob(\"*.jpg\"):\n",
        "    OMG.append(file)\n",
        "\n",
        "for i in OMG:\n",
        "  img = tf.keras.preprocessing.image.load_img('/content/drive/My Drive/DOG_N_CAT/cats_and_dogs_filtered/test/'+str(i),target_size=(150, 150))\n",
        "  img = np.asarray(img)\n",
        "  img = np.expand_dims(img, axis=0)\n",
        "  result = DATA_LOAD.predict_classes(img)\n",
        "  plt.xlabel(\"KOCENG\" if int(result) == 0 else \"ANJENG\")\n",
        "\n",
        "\n",
        "plt.figure(figsize=(100,100))\n",
        "for i in range(18):\n",
        "    plt.subplot(3,6,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    img = tf.keras.preprocessing.image.load_img('/content/drive/My Drive/DOG_N_CAT/cats_and_dogs_filtered/test/'+str(OMG[i]),target_size=(150, 150))\n",
        "    img = np.asarray(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    plt.imshow(img)\n",
        "    plt.xlabel(OMJ[i])\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Br7NfF1k-J9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "DATA_LOAD = tf.keras.models.load_model('/content/drive/My Drive/DOG_N_CAT/BAGUS_04022020_1706_val_acc_077.h5')\n",
        "\n",
        "def prediksi_semua(x):\n",
        "  img = tf.keras.preprocessing.image.load_img(x,target_size=(150, 150))\n",
        "  img = np.asarray(img)\n",
        "  #plt.figure()\n",
        "  plt.imshow(img)\n",
        "\n",
        "  img = np.expand_dims(img, axis=0)\n",
        "\n",
        "  result = DATA_LOAD.predict_classes(img)\n",
        "  plt.xlabel(\"KOCENG\" if int(result) == 0 else \"ANJENG\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/DOG_N_CAT/cats_and_dogs_filtered/test/\")\n",
        "for file in glob.glob(\"*.jpg\"):\n",
        "\n",
        "    prediksi_semua(file)    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKul4W6400R7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls /content/drive/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x_VPwcK1VPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model_new.fit_generator(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=total_train // batch_size,\n",
        "    epochs=50,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=total_val // batch_size\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5l8OkQb5tZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs_range = range(50)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXasSk7h5v83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('/content/drive/My Drive/DOG_N_CAT/BAGUS_04022020_0853.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88wBaZ626BA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model_new.fit_generator(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=total_train // batch_size,\n",
        "    epochs=50,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=total_val // batch_size\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmpugOcl9h2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_new.save('/content/drive/My Drive/DOG_N_CAT/BAGUS_04022020_0910_VAL_ACC_078.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "es4_UFhV1iN8",
        "colab": {}
      },
      "source": [
        "model_new2 = Sequential([\n",
        "    Conv2D(64, 3, padding='same', activation='relu',input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Dropout(0.2),\n",
        "    Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(256, 3, padding='same', activation='relu'),\n",
        "    Conv2D(256, 3, padding='same', activation='relu'),\n",
        "    Conv2D(256, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(512, 3, padding='same', activation='relu'),\n",
        "    Conv2D(512, 3, padding='same', activation='relu'),\n",
        "    Conv2D(512, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),    \n",
        "    Conv2D(512, 3, padding='same', activation='relu'),\n",
        "    Conv2D(512, 3, padding='same', activation='relu'),\n",
        "    Conv2D(512, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "\n",
        "    Dropout(0.2),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_new2.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_new2.summary()\n",
        "\n",
        "history = model_new2.fit_generator(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=total_train // batch_size,\n",
        "    epochs=50,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=total_val // batch_size\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHU3NEYCI4fM",
        "colab_type": "text"
      },
      "source": [
        "# **Note**\n",
        "\n",
        "setelah dibandingkan , model_new dengan arsitektur yang sederhana lebih cepat convergen val_accuracynya (walaupun dengan beberapa kali iterasi/fit yang masing masing 50 epochs)\n",
        "\n",
        "untuk model_new2 dengan arsitektur yang mendekati VGG16 converen tidak tecapai , val_accuracy rendah hanya pada kisaran 0.4 ~ 0.5 , dan memakan resource yang banyak."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sf-FQpNwLHsd",
        "colab_type": "text"
      },
      "source": [
        "# RE-Use model\n",
        "Yang telah di train dan menghasilan akurasi lumayan baik 0.79 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVKZcheVKqYr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model_reuse = tf.keras.models.load_model('/content/drive/My Drive/DOG_N_CAT/BAGUS_04022020_0910_VAL_ACC_078.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-DTfBlnLV5p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "#test_image =tf.keras.preprocessing.image.load_img('/content/drive/My Drive/DOG_N_CAT/cats_and_dogs_filtered/validation/cats/cat.2000.jpg',target_size =(150,150))\n",
        "#test_image =tf.keras.preprocessing.image.load_img('/content/drive/My Drive/DOG_N_CAT/cats_and_dogs_filtered/validation/dogs/dog.2000.jpg',target_size =(150,150))\n",
        "#test_image =tf.keras.preprocessing.image.img_to_array(test_image)\n",
        "#test_image =np.expand_dims(test_image, axis =0)\n",
        "#result = model_reuse.predict(test_image)\n",
        "\n",
        "#print(result)\n",
        "#if result[0][0] >= 0.5:\n",
        "#    prediction = 'dog'\n",
        "#else:\n",
        "#    prediction = 'cat'\n",
        "#print(prediction)\n",
        "\n",
        "\n",
        "#image_path=\"test_set/cat2.png\"\n",
        "#img = image.load_img(image_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "test_image =tf.keras.preprocessing.image.load_img('/content/drive/My Drive/DOG_N_CAT/cats_and_dogs_filtered/validation/dogs/dog.2000.jpg',target_size =(150,150))\n",
        "plt.imshow(test_image)\n",
        "test_image = np.expand_dims(test_image, axis=0)\n",
        "result=model_reuse.predict_classes(test_image)\n",
        "plt.title(get_label_name(result[0][0]))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZEPBZI4PFoe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}